<!DOCTYPE html>
<html lang="pl">
<head>
	<meta&nbspcharset="UTF-8">
	<title>4. Zaufanie</title>
	<style>
	p    {line-height: 160%; font-size: 120%; text-align: left;}
</style>
</head>

<body style="margin: 4% 3% 100px 4%;">
<h1>4. Zaufanie</h1> 
<p>
Rok 2016 był przełomowy dla samochodów autonomicznych, pierwszym z&nbspnich było Audi A7, które podczas testowej jazdy uczestniczyło 2&nbspinżynierów: jeden kierował, drugi monitorował. Na desce rozdzielczej, na ekranie pojawił się komunikat o&nbspautopilocie, które gotowość sygnalizowały światłem 2&nbspprzyciski. Inspiracją dla takiego rozwiązania był system obsługujący amerykański arsenał jądrowy, w&nbspktórym do wystrzelenia pocisku konieczne jest jednoczesne przekręcenie dwóch kluczyków, co ma zapobiec błędom. Kierownica wycofała się w&nbspgłąb deski rozdzielczej i&nbspzaczęła sama skręcać, z&nbspniesamowitą precyzją dostosowując trasę auta do linii na drodze. Moment ten był prawdziwie zjawiskowy, lecz jego niezwykłość minęła w&nbspmgnieniu oka, prędko ustępując wcześniejszej banalności. Inżynierowie przeszli test nagłego hamowania pojazdu przed nimi, Audi samowolnie podjęło nieudaną (bo ktoś wjechał w&nbspmartwe pole) decyzję o&nbspzmianie pasa. Zdarzenie to wręcz wzbudziło niepokój, ponieważ kierowcy testujący powinni być stale przygotowani do przejęcia kontroli. Również prawo nie przewidywało jak się zachować w&nbspsytuacji, gdy kierowca nie ma rąk na kierownicy. Samochody nowe technologie otrzymywały w&nbspszybkim tempie (np. samoczynne parkowanie, automatyczne unikanie kolizji itp.), jednak użytkownicy nie zawsze od razu załapali ich możliwości. Przykładem jest film, w&nbspktórym kierowca Volvo nie wykupił systemu automatycznego hamowania i&nbspwpadł prosto w&nbspśmiałka – pieszego. Innym przykładem jest autopilot Tesli, który nie wykrywał linii jezdni i&nbspwjeżdżał wprost pod nadjeżdżające auta.
<br>
<br>
Takie systemy  są przykładem poszczególnych projektów designerskich, to czy technologia zadziała nie zależy jedynie od inżyniera, lecz także od ludzi, czy załapią jak się nimi posługiwać, czy możemy im zaufać. Wzbudzenie zaufania potrzebowało odpowiedniego zaprojektowania, żeby ludzie czuli się bezpieczni. Ludzie na nagraniach, w&nbspktórych technologia są przerażeni, dlatego, że zawiódł ich design. Sekret tkwi w&nbsptym, że potrafimy zaufać maszynom tylko wtedy, kiedy próbują one zdobyć nasze zaufanie, tak jak robią to inni ludzie. 
<br>
<br>
Zadaniem <b>Briana Lathropa</b> jest poszukiwanie rozwiązań designerskich, dzięki którym kierowcy zaufają autonomicznemu Audi&nbspA7. Lathrop jest doktorem psychologii, zajmuje się projektowaniem doświadczeń użytkownika w&nbsp<i>Electronics Research Laboratory</i>, spółce Volkswagena. Początkowo zajmował się prostym lutowaniem, ostatecznie zaczął pracować nad projektem do kabin samochodów koncepcyjnych, futurystycznych. Zauważył ogrom i&nbspnieład przycisków za kierownicą luksusowego modelu, więc wpadł na pomysł umieszczenia  ich na ekranie dotykowym. Samochody autonomiczne potrafi wtenczas przemierzać trasę wyścigową na szczyt Pikes Peak. Brian był przygotowany na wynalazki, zdobywał doświadczenie w&nbspNASA projektując wyświetlacze nahełmowe. w&nbspprzypadku katastrof lotniczych błąd może wystąpić raz na 16h, w&nbspsamochodach wypadek może zdarzyć się co sekundę.  Przy pracy przydała mu się książka „Taming HAL” <i>Asafa Deganiego</i>, nawiązuje do AI z&nbspfilmu <i>2001: Odyseja kosmiczna</i>, przedstawiony był zarys historii i&nbspkatastrof autonomizacji. Potrzebne było zaprojektowanie urządzenia z&nbspłatwo nawigowalnym interfejsem, ze spójną strukturą i&nbspinformacjami zwrotnymi, potwierdzającymi działanie.  
<br>
<br>
<b>Lathrop opracował filozofię designu „<i>trzy plus jeden</i>”</b>, w&nbspktórej urządzenie (samochód) musi spełniać 3&nbspwymogi i&nbspjeden dodatkowy: 1)&nbspczy auto działa na autopilocie, 2)&nbsp„zasada rozlanej klapy”, żeby przejęcie kontroli nie wiązało się z&nbspzaskoczeniem i&nbspszokiem, 3)&nbspprzejrzyste informowanie o&nbsptym, co widzi pojazd, +1)&nbspprzejście między trybami odpowiednio sygnalizowane, żeby nie było niedomówień. 
<br>
<br>
W przyszłości maszyny będą musiały nie tylko dostosować się do naszych potrzeb i&nbspoczekiwań, ale także zdobyć nasze zaufanie. a&nbspto będzie wymagać wielu subtelnych rozwiązań. Takim rozwiązaniem jest przykład kombinezonu <i>fuseproject</i>, który wspomaga starszych ludzi okalającym ich materiałem z&nbspdodatkowymi silniczkami, wspomagające mięśnie, uruchamiające się kiedy potrzeba. AI w&nbspkombinezonie przewiduje intencje ruchowe, działając niemalże naturalnie. Jedynym problemem byłoby pozbawianie ludzi poczucia kontroli, czując się jak marionetka, gorzej, jeśli kombinezon źle odczyta sygnał zmuszając kogoś do wykonania nieplanowanego ruchu, przez co można stracić zaufanie. Potrzebny był nowatorski design, w&nbspktórym po dotknięciu silniczków, te by się uruchamiały. Najpierw mówi użytkownikowi co zamierza zrobić i&nbspumożliwia potwierdzenie czynności, by później przekazać informację zwrotną. Jest przykładem, jak zachowanie stało się materiałem projektantów, oraz dostosowanie do tego technologii. Design powinien być wyczulony na to, co uważamy za właściwe, taktowne lub uprzejme, na tym polega ludzkie zachowanie. 
<br>
<br>
W latach 90. socjolog <b>Clifford Nass</b> dokonał jednego z&nbspnajbardziej osobliwych odkryć w&nbsphistorii badań nad interakcjami człowiek–komputer. Badał on ludzkie postrzeganie komputerów, jak je używamy i&nbspjakie uczucia do nich żywimy. Szczególnie interesowała go kwestia uprzejmości, która była kwantyfikowana. Np. uczymy kogoś czegoś, a&nbsppotem pytamy, jak nam poszło; tutaj zależało od uprzejmości ludzkiej, bądź krytyki. To samo chciał sprawdzić w&nbsprelacjach z&nbspkomputerem, badania potwierdziły, że ludzie są uprzejmi dla urządzenia, które znają. Zalecił testerom wykonanie kilku zadań, potem ocenienie design zainstalowanego oprogramowania: jedni robili na tych, które znali, inni na nieużywanych przez nich wcześniej. Ta druga grupa ostrzej krytykowała, gdy pierwsza była bardziej uprzejma, zwracając im o&nbspto uwagę to zaprzeczali, jednak wciąż byli uprzejmi. Nass przeprowadził kilka eksperymentów, np. z&nbsppochwałami komputera dla użytkowników itp. Clifford potwierdził, że komputery nie są już jedynie narzędziami, lecz jest obecne nawiązanie z&nbspnimi relacji. Mózg wyewoluował do poruszania się w&nbsp2 rzeczywistościach: fizycznej i&nbspspołecznej, komputery mimo bycia czymś materialnym, wciągają nas w&nbspróżne interakcje, wyzwalają emocje, relacje człowiek-maszyna, co przyczyniło się do tego, że i&nbspone będą przestrzegać norm i&nbspzachowywać ton. 
<br>
<br>
Takie coś przyczynia się do sytuacji, w&nbspktórej pełni świadomi ludzie zerkają na otrzymany SMS, a&nbsposoba siedząca obok czuje zagrożenie, że nie skupiamy uwagi na drodze, tylko na SMS-ie. Ona jako osoba skupiona na drodze przetworzy więcej, ale niekoniecznie potrzebne informacje, nie potrafi przewidzieć kolejnego ruchu kierowcy. Tak samo jest z&nbspurządzeniami, potrzebna jest komunikacja i&nbspinformacje zwrotne, że urządzenie widzi to co my.  Za pomocą ekranu samochód informuje o&nbspkolejnych manewrach, przez co czujemy większą ufność, że ktoś nas wziął na przejażdżkę, a&nbspnie uprowadził. 
<br>
<br>
<b>Paul Grice</b>, filozof, uznał, że komunikacją rządzą niewypowiedziane reguły konwersacyjne. Ich sedno sprowadza się do mówienia w&nbspsposób zrozumiały i&nbsppodawania wymaganej ilości informacji, zgodne z&nbspprawdą.  Reguły Grice’a mówią o&nbspuprzejmości, zrozumieniu oraz prawidłowego określeniu zakresy wiedzy, za nieuprzejme zaliczymy przekrzykiwanie, przerywanie, błędne interpretowanie. Reguły te ściśle związane są z&nbspdesignem. Przykładem jest Pan Spinacz, asystent MS Office, który nieproszony pojawiał się na ekranie i&nbspwręcz przeszkadzał przy pracy. Nie potrafił nauczyć się niczego o&nbspużytkowniku: imienia, peryferiach, stylu itp. Będąc zawsze uśmiechnięty niemalże sprawiał wrażenie drwienia z&nbspużytkownika. <i>Ludzie oczekują, że komputery będą się zachowywać jak osoby z&nbspkrwi i&nbspkości. a&nbspgdy technologia nie reaguje w&nbspsposób zgodny z&nbspprzyjętymi wzorcami, są poirytowani</i>. Wymagane jest w&nbspdesignie i&nbspkonwersacji to, żeby stawała się łatwiejsza i&nbspbardziej przejrzysta. w&nbsprelacjach międzyludzkich, odpowiedzią czy wszystko jest OK może być nieświadoma mowa ciała.  
<br>
<br>
Do przedstawienia ludziom autonomicznego auta, <b>Erik Glaser</b> i&nbspjego zespół zebrał pieszych i&nbspsprawdzał, jak będą reagować na samochód bez kierowcy. w&nbsptaki sposób będą w&nbspstanie stwierdzić i&nbspprzekonać się do technologii. Namalowali odpowiednie linie na jezdni, przejścia dla pieszych itp. Auto posiadało zaciemnioną szybę, a&nbsppiesi mieli przejść przez jezdnię, gdy uznają, że jest bezpiecznie. Zakładano, że piesi będą krzyczeć, uciekać itp. <i>wynik był wręcz przeciwny</i> – nie mieli cienia obawy i&nbspbeztrosko wkraczali na jezdnię. Na ich zachowanie myślano, że wpływały zewnętrzne wyświetlacze, informujące, że samochód ich widzi, jednak piesi tych wyświetlaczy nie dostrzegali. Piesi byli pewni siebie, ponieważ samochód <i>zachowywał kulturę jazdy i&nbspprzestrzegał obyczajów</i>, że samochód zwalnia jak widzi pieszego, nie zamierza wcisnąć gazu ani wyrządzić nikomu krzywdy. Na przykładzie Tesli, szybkie wdrażanie technologii i&nbspuczenie się na błędach przyczynia się do rozwoju. Jest to również klucz do designu przyszłości – gdzie ludzie nieświadomie będą wykorzystywać technologie, będącą bardziej ludzką. Glaser już na studiach opracował robota, który serwował przekąski i&nbspgdy użytkownik wybrał te niezdrowe, nakłaniał do wybrania zdrowszego stylu odżywiania. 
<br>
<br>
Już w&nbspNASA opracowywano możliwość przejęcia kontroli przez pilota nad autonomicznym statkiem, zupełnie jak jeździec konia, gdy chwyci wodze (ta linka przyczepiona do pyska). Potrzebna buła gwarancja bezpieczeństwa oraz nie podjęcie samodzielnych decyzji przez maszynę. Lathrop chciał stworzyć pojazd, w&nbspktórym nie dałoby się dopuścić do wypadku (bazując na zmysłach i&nbspinstynkcie konia). Samochód potrzebuje technologii: kamer, mapy, czujników kontrolujących kierowcę. Gdy kierowca stracił kontrolę (zdjął ręce z&nbspkierownicy), maszyna automatycznie przejmowała ster, z&nbspmożliwością przejęcia kontroli. 
<br>
<br>
Początkowo opracowując autopilota, inżynierowi byli zdania, że odpowiedni będzie do tego przycisk. Przykładem dobrego zastosowania takiego przycisku były: aparat <i>Polaroid  Edwina Landa</i>, który przyspieszał proces wywoływania zdjęć; <i>ekspres do kawy Nespresso</i>; <i>Amazon</i> pozwalający kupić towar jednym przyciskiem; przycisk alarmowy Mladena Barbarica. w&nbspsamochodzie wciśnięcie tego przycisku wiązałoby się jedynie z&nbspintencjami kierowcy, nie zwracając uwagi, czy ma pod kontrolą pojazd. Chciał, by pojazdy działały autonomicznie wtedy, gdy jest to potrzebne, bez wydawania poleceń, żeby działał bardziej naturalnie i&nbspbył dostosowany pod użytkownika. Kolejnym etapem Lathropa było wyposażenie maszyny w&nbspinstynkty, czujniki, które by właściwie reagowały na ludzkie zachowanie. Aktualnie wiele samochodów jest w&nbsptaki sposób w&nbspstanie zatrzymać pojazd, jak kierowca np. zaśnie. Żeby zaufać maszynom, potrzebne jest poczucie, że wiedzą, czego nam potrzeba. Gdy model mentalny nie zgadza się z&nbsprzeczywistością, to jest  błędem projektowym. Błędem jest również niepotrzebne nadawanie nazw, które niekoniecznie spełniają oczekiwania użytkowników. 
<br>
<br>
Jednym z&nbsptesterem Tesli był <i>Joshua Brown</i>, kupując samochód nabył filozofię designu: <i>Tesla przekracza granice tego, na co byliśmy gotowi</i>. Samochód jednak nie potrafił dostrzec skręcającej ciężarówki, przez co Brown zginął na miejscu. Audi wypuszczając SUV-a było przygotowane na takie sytuacje i&nbspnie można było oderwać rąk od kierownicy na dłużej niż kilka sekund, ponieważ wybrzmiewał dźwięk. Auto dawało sygnały kierowcy, że to wciąż on prowadzi. Posiadał odpowiednie systemu bezpieczeństwa, które potrafiły reagować na zagrożenie. Wydany został również raport nt. Browna, w&nbspktórym stwierdzono, że autopilot był używany niezgodnie z&nbspprzeznaczeniem, a&nbspkierowca powinien stale zachowywać czujność. Innym przykładem błędów maszyn był śmiertelny wypadek spowodowany autem Ubera, bądź przypadkowy przycisk wysyłający alert o&nbspzbliżającym się pocisku jądrowym, w&nbspktórym zabrakło czytelnego sposobu potwierdzenia opcji. Ludzie niekoniecznie przestrzegają zasad opisanych w&nbspinstrukcjach urządzeń. Oczekujemy, że ich działanie będzie intuicyjne, nawet jeśli nie mieliśmy z&nbspnim wcześniej styczności, w&nbspprzeciwnym razie wkrada się zamęt. 
<br>
<br>
Taki problem odgrywa się również wśród asystentów głosowych, przy których użytkownicy zakładają, że rzeczywiście potrafią załatwić codzienne sprawy. Ich możliwości nie są w&nbspstanie sprostać oczekiwaniom interfejsu, który próbuje naśladować. Słowo mówione jest najbardziej  elastycznym interfejsem, przekazujące wszelakie informacje, jednak w&nbspich wypadku należy ubierać słowa tak, by algorytm im sprostał. Kiedy nie dają sobie rady, sypią żartami. Asystenci głosowi są w&nbspstanie sprostać wieloma umiejętności, gorzej jest z&nbspodkryciem i&nbspspamiętaniem umiejętności. Wciąż jednak wymagane jest stałe rozwijanie technologii. 
<br>
<br>
W środowisku Don Norman jest znany jako osoba, która projektuje wgłębienia itp. wskazując jak pociągnąć, wcisnąć odpowiednie kontrolki. Za początki tej koncepcji uznaje się <b>Alphonseʼa Chapanisa</b>, który oznaczył kontrolki w&nbspkokpicie samolotu. Dziś takie kontroli reprezentuje zlepek pikseli – ikony, nacechowane odpowiednimi kształtami i&nbspkolorami.  Takie oznaczenia nie zawsze są w&nbspstanie sprostać naszym oczekiwaniom. 
<br>
<br>
<b>Sameer Saproo</b>, badacz, który testował gogle do VR, zainspirował się <i>Matrixem</i>. Dzięki takiemu urządzeniu można odnieść wrażenie, że technologia mogąca nas przenieść do VR jest na wyciągnięcie ręki. Celem symulacji było pokazanie, że AI jest w&nbspstanie nauczyć się prowadzenia samochodu oraz stylu jazdy. Uważał za problem samochodów autonomicznych to, w&nbspjaki sposób będą w&nbspstanie się zachować na drodze. Dążył do stworzenia auta dynamicznie reagującego na ludzkie uczucia i&nbsppragnienia: jadącego szybko, gdy chcemy się z&nbspkimś ścigać lub zależy nam na czasie, albo niespiesznie, kiedy mamy ochotę po prostu się zrelaksować i&nbspnapawać mijanym za szybą krajobrazem. Chciał, aby samochód zachowywał się jak sługa, zaspokajając zachcianki kierowcy, auta będą swego rodzaju formą życia, jeśli będą wykonywać zadania lepiej niż ludzie. Nasze życie stanie się bardziej komfortowe, a&nbspujście dla naszej sprawczości odnajdziemy w&nbspczymś innym. Jego dowodem dla tej tezy było to, jak iPhone i&nbspekrany dotykowe zmieniły oblicze świata. Już przed trzydziestu laty informatycy pracujący w&nbspXerox PARC przewidywali powstanie gadżetu pozwalającego wykonywać skomplikowane zadania za dotknięciem ekranu bez konieczności wpisywania poleceń na klawiaturze. Teraz komputera używamy bez konieczności uczenia się jego obsługi. 
</p>
<br><h2 style="text-align: right"><a href="ux2.html">< 3. Błąd</a>&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp<a href="ux5.html">5. Metafora ></a></h2>

</body>
</html>
